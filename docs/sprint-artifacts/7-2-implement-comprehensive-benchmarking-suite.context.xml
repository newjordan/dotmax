<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>7</epicId>
    <storyId>2</storyId>
    <title>Implement Comprehensive Benchmarking Suite</title>
    <status>drafted</status>
    <generatedAt>2025-11-25</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/7-2-implement-comprehensive-benchmarking-suite.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>library maintainer</asA>
    <iWant>a comprehensive benchmarking suite that measures all critical performance paths</iWant>
    <soThat>I can validate performance targets, detect regressions, and provide evidence-based performance claims to users</soThat>
    <tasks>
      <task id="1" name="Audit and Consolidate Existing Benchmarks" ac="4">
        <subtask id="1.1">Inventory all existing benchmark files in benches/</subtask>
        <subtask id="1.2">Run cargo bench --all-features to verify current state</subtask>
        <subtask id="1.3">Identify gaps between existing benchmarks and AC requirements</subtask>
        <subtask id="1.4">List benchmarks to create vs. enhance</subtask>
        <subtask id="1.5">Document current benchmark coverage</subtask>
      </task>
      <task id="2" name="Create Core Rendering Benchmarks" ac="1">
        <subtask id="2.1">Create benches/core_rendering.rs if not exists</subtask>
        <subtask id="2.2">Add grid_creation benchmark group with sizes: 40x12, 80x24, 160x48, 200x50</subtask>
        <subtask id="2.3">Add dot_operations benchmark for set_dot (1000 ops, 10000 ops)</subtask>
        <subtask id="2.4">Add unicode_conversion benchmark for to_char across full grid</subtask>
        <subtask id="2.5">Add clear_grid benchmark for grid.clear() performance</subtask>
        <subtask id="2.6">Register in Cargo.toml [[bench]] section</subtask>
        <subtask id="2.7">Run and verify all benchmarks produce results</subtask>
      </task>
      <task id="3" name="Create/Enhance Image Processing Benchmarks" ac="2,5">
        <subtask id="3.1">Create benches/image_processing.rs consolidating existing image benchmarks</subtask>
        <subtask id="3.2">Add image_load benchmark (PNG, JPG test images)</subtask>
        <subtask id="3.3">Add image_resize benchmark (various aspect ratios)</subtask>
        <subtask id="3.4">Add dither_algorithms benchmark comparing all methods</subtask>
        <subtask id="3.5">Add threshold benchmark for Otsu algorithm</subtask>
        <subtask id="3.6">Add full_pipeline benchmark - 80x24 end-to-end (&lt;25ms target)</subtask>
        <subtask id="3.7">Add pipeline benchmarks for 40x12, 160x48, 200x50 sizes</subtask>
        <subtask id="3.8">Feature-gate with #[cfg(feature = "image")]</subtask>
        <subtask id="3.9">Register in Cargo.toml [[bench]] section</subtask>
        <subtask id="3.10">Verify 80x24 benchmark meets &lt;25ms target</subtask>
      </task>
      <task id="4" name="Enhance Animation Benchmarks" ac="3,6">
        <subtask id="4.1">Review existing benches/animation.rs</subtask>
        <subtask id="4.2">Add frame_swap benchmark for FrameBuffer.swap_buffers()</subtask>
        <subtask id="4.3">Add differential_render benchmark for DifferentialRenderer</subtask>
        <subtask id="4.4">Add 60fps_sustained benchmark - 100 frames at target rate</subtask>
        <subtask id="4.5">Add frame_preparation benchmark for frame setup time</subtask>
        <subtask id="4.6">Verify frame timing &lt;16.67ms for 60fps target</subtask>
        <subtask id="4.7">Document animation benchmark methodology</subtask>
      </task>
      <task id="5" name="Create CI Benchmark Workflow" ac="7">
        <subtask id="5.1">Create .github/workflows/benchmark.yml</subtask>
        <subtask id="5.2">Configure trigger on push to main branch</subtask>
        <subtask id="5.3">Set up Rust toolchain with criterion</subtask>
        <subtask id="5.4">Run cargo bench --all-features</subtask>
        <subtask id="5.5">Upload benchmark artifacts</subtask>
        <subtask id="5.6">Store results for historical comparison</subtask>
        <subtask id="5.7">Test workflow locally with act or similar</subtask>
      </task>
      <task id="6" name="Configure Regression Detection" ac="8">
        <subtask id="6.1">Research criterion baseline comparison options</subtask>
        <subtask id="6.2">Configure benchmark baseline storage in CI</subtask>
        <subtask id="6.3">Add regression check step (>10% slowdown = failure)</subtask>
        <subtask id="6.4">Configure PR comment or status check on regression</subtask>
        <subtask id="6.5">Test regression detection with intentional slowdown</subtask>
        <subtask id="6.6">Document regression detection configuration</subtask>
      </task>
      <task id="7" name="Document Benchmark Results" ac="9">
        <subtask id="7.1">Run full benchmark suite and collect results</subtask>
        <subtask id="7.2">Create performance table for README.md</subtask>
        <subtask id="7.3">Include key metrics: grid_creation, image_pipeline, animation_fps</subtask>
        <subtask id="7.4">Document test environment (CPU, OS, Rust version)</subtask>
        <subtask id="7.5">Add performance badge or section to README</subtask>
        <subtask id="7.6">Document how users can run benchmarks themselves</subtask>
      </task>
      <task id="8" name="Final Validation" ac="all">
        <subtask id="8.1">Run cargo bench --all-features - all benchmarks pass</subtask>
        <subtask id="8.2">Verify cargo bench without features still works (core only)</subtask>
        <subtask id="8.3">Verify 80x24 image pipeline &lt;25ms</subtask>
        <subtask id="8.4">Verify animation frame time &lt;16.67ms</subtask>
        <subtask id="8.5">Verify CI workflow runs successfully</subtask>
        <subtask id="8.6">Verify README includes performance section</subtask>
        <subtask id="8.7">Run cargo clippy on benchmark code - zero warnings</subtask>
        <subtask id="8.8">Review all 9 ACs with evidence</subtask>
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="AC1" title="Core rendering benchmarks exist">
      <requirement>benches/core_rendering.rs exists with benchmark groups for: grid_creation - BrailleGrid::new() for various sizes, dot_operations - set_dot/clear operations, unicode_conversion - to_char() conversion performance</requirement>
      <requirement>All benchmarks use criterion with proper configuration</requirement>
    </criterion>
    <criterion id="AC2" title="Image processing benchmarks exist">
      <requirement>benches/image_processing.rs exists with benchmark groups for: image_load, image_resize, dither_algorithms, threshold, full_pipeline</requirement>
      <requirement>Feature-gated with #[cfg(feature = "image")]</requirement>
    </criterion>
    <criterion id="AC3" title="Animation benchmarks exist">
      <requirement>benches/animation.rs enhanced with: frame_swap, differential_render, 60fps_sustained</requirement>
      <requirement>Tests both FrameBuffer and AnimationLoop</requirement>
    </criterion>
    <criterion id="AC4" title="All benchmarks run successfully">
      <requirement>cargo bench --all-features completes without errors</requirement>
      <requirement>All benchmark groups execute and produce results</requirement>
      <requirement>No compilation warnings in benchmark code</requirement>
    </criterion>
    <criterion id="AC5" title="Image render &lt;25ms target">
      <requirement>80x24 terminal benchmark mean execution time &lt;25ms</requirement>
      <requirement>Benchmark result documented with specific timing</requirement>
      <requirement>Multiple image sizes benchmarked (small, medium, large)</requirement>
    </criterion>
    <criterion id="AC6" title="60fps animation achievable">
      <requirement>Frame timing benchmark shows &lt;16.67ms per frame</requirement>
      <requirement>Sustained 60fps validated over 100+ frames</requirement>
      <requirement>No frame drops during benchmark execution</requirement>
    </criterion>
    <criterion id="AC7" title="CI benchmark integration">
      <requirement>.github/workflows/benchmark.yml exists</requirement>
      <requirement>Runs benchmarks on main branch pushes</requirement>
      <requirement>Stores benchmark artifacts for historical comparison</requirement>
    </criterion>
    <criterion id="AC8" title="Regression detection configured">
      <requirement>CI workflow detects >10% regression</requirement>
      <requirement>Comments on PR if regression detected (or fails CI)</requirement>
      <requirement>Uses criterion's comparison features or similar</requirement>
    </criterion>
    <criterion id="AC9" title="Benchmark results documented">
      <requirement>README.md includes performance table with key metrics</requirement>
      <requirement>Documents test environment (hardware, OS)</requirement>
      <requirement>Shows baseline performance for common operations</requirement>
    </criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="docs/sprint-artifacts/tech-spec-epic-7.md" title="Epic 7 Tech Spec" section="Story 7.2: Benchmarking Suite">
        Authoritative acceptance criteria for benchmarking (AC7.2.1-7.2.9). Performance targets: &lt;25ms image render, 60fps animation, &lt;1ms buffer swap.
      </doc>
      <doc path="docs/architecture.md" title="Architecture Document" section="Performance Considerations">
        Performance strategy: measure-first optimization, criterion benchmarks, flamegraph profiling. Targets: &lt;25ms render, 60fps minimum, &lt;5MB memory.
      </doc>
      <doc path="README.md" title="README" section="Performance">
        Current performance claims: &lt;50ms image rendering, 60fps animation. Needs performance table with benchmark evidence (AC9).
      </doc>
      <doc path=".github/workflows/benchmark.yml" title="Existing Benchmark Workflow">
        Basic CI workflow exists. Runs on main branch pushes, uploads criterion results. Missing: regression detection, PR comments on regression.
      </doc>
      <doc path=".github/workflows/ci.yml" title="Main CI Workflow">
        Cross-platform testing (Windows, Linux, macOS), clippy, fmt, security audit, MSRV check, cargo-deny.
      </doc>
    </docs>
    <code>
      <!-- Existing Benchmark Files -->
      <file path="benches/rendering.rs" kind="benchmark" symbol="bench_braille_grid_creation, bench_grid_clear, bench_unicode_conversion, bench_to_unicode_grid" lines="1-85" reason="Core rendering benchmarks exist - may need consolidation to core_rendering.rs per AC1"/>
      <file path="benches/animation.rs" kind="benchmark" symbol="bench_swap_buffers, bench_frame_timer, bench_differential" lines="1-355" reason="Animation benchmarks already exist - has frame_swap, differential_render. Missing: 60fps_sustained benchmark (AC3)"/>
      <file path="benches/extreme_image_pipeline.rs" kind="benchmark" reason="Large image benchmarks - may consolidate into image_processing.rs"/>
      <file path="benches/image_resize.rs" kind="benchmark" reason="Image resizing benchmarks - consolidate into image_processing.rs per AC2"/>
      <file path="benches/image_conversion.rs" kind="benchmark" reason="Image conversion benchmarks - consolidate into image_processing.rs per AC2"/>
      <file path="benches/dithering.rs" kind="benchmark" reason="Dithering algorithm benchmarks - consolidate into image_processing.rs per AC2"/>
      <file path="benches/svg_rendering.rs" kind="benchmark" reason="SVG rasterization benchmarks - may consolidate"/>
      <file path="benches/braille_mapping.rs" kind="benchmark" reason="Pixel-to-braille mapping benchmarks"/>
      <file path="benches/color_rendering.rs" kind="benchmark" reason="Color rendering benchmarks"/>
      <file path="benches/density.rs" kind="benchmark" reason="Character density benchmarks"/>
      <file path="benches/primitives.rs" kind="benchmark" reason="Drawing primitive benchmarks"/>
      <file path="benches/color_conversion.rs" kind="benchmark" reason="RGB/ANSI color conversion benchmarks"/>
      <file path="benches/color_schemes.rs" kind="benchmark" reason="Color scheme application benchmarks"/>
      <file path="benches/color_apply.rs" kind="benchmark" reason="Color application benchmarks"/>
      <!-- Core Library Types -->
      <file path="src/lib.rs" kind="module" symbol="BrailleGrid, TerminalRenderer, Color, ColorScheme, DotmaxError, FrameBuffer, AnimationLoop" lines="1-139" reason="Public API re-exports - benchmark targets"/>
      <file path="src/grid.rs" kind="module" symbol="BrailleGrid::new, set_dot, clear, cell_to_braille_char, to_unicode_grid" reason="Core grid operations to benchmark (AC1)"/>
      <file path="src/animation/mod.rs" kind="module" symbol="FrameBuffer, FrameTimer, AnimationLoop, DifferentialRenderer" reason="Animation types to benchmark (AC3, AC6)"/>
      <file path="src/image/mod.rs" kind="module" symbol="ImageRenderer, DitherMethod, resize, threshold" reason="Image pipeline to benchmark (AC2, AC5)"/>
      <!-- CI/CD -->
      <file path="Cargo.toml" kind="config" lines="36-58" reason="Benchmark registration - need to add core_rendering.rs, image_processing.rs"/>
    </code>
    <dependencies>
      <rust>
        <core>
          <dep name="ratatui" version="0.29">Terminal UI framework</dep>
          <dep name="crossterm" version="0.29">Cross-platform terminal I/O</dep>
          <dep name="thiserror" version="2.0">Error handling derive macros</dep>
          <dep name="tracing" version="0.1">Structured logging</dep>
        </core>
        <optional>
          <dep name="image" version="0.25" feature="image">Image loading (PNG, JPG, etc.)</dep>
          <dep name="imageproc" version="0.24" feature="image">Image processing algorithms</dep>
          <dep name="resvg" version="0.38" feature="svg">SVG rasterization</dep>
          <dep name="usvg" version="0.38" feature="svg">SVG parsing</dep>
        </optional>
        <dev>
          <dep name="criterion" version="0.7" features="html_reports">Benchmarking framework - PRIMARY for this story</dep>
          <dep name="tracing-subscriber" version="0.3">Log output for tests</dep>
          <dep name="tempfile" version="3.10">Temporary file handling</dep>
        </dev>
      </rust>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="architecture">Measure-first optimization: No optimization without benchmark proof (ADR-0007)</constraint>
    <constraint type="architecture">Feature flags: Core benchmarks must work without features; image benchmarks feature-gated</constraint>
    <constraint type="ci">CI benchmark integration required - runs on main branch pushes (AC7)</constraint>
    <constraint type="ci">Regression detection: &gt;10% slowdown must fail or alert (AC8)</constraint>
    <constraint type="performance">Image-to-braille (80x24): &lt;25ms target (NFR-P1)</constraint>
    <constraint type="performance">Animation: 60fps minimum, &lt;16.67ms per frame (NFR-P2)</constraint>
    <constraint type="performance">Buffer swap: &lt;1ms (NFR-P2)</constraint>
    <constraint type="performance">Grid creation: &lt;1ms (NFR-P1)</constraint>
    <constraint type="quality">Zero clippy warnings in benchmark code (AC4)</constraint>
    <constraint type="quality">All benchmarks must use criterion with proper configuration</constraint>
  </constraints>

  <interfaces>
    <interface name="criterion" kind="benchmark-framework">
      <signature>criterion_group!, criterion_main!, Criterion, BenchmarkId</signature>
      <path>benches/*.rs</path>
      <usage>All benchmarks use criterion for statistical analysis and HTML reports</usage>
    </interface>
    <interface name="BrailleGrid" kind="struct">
      <signature>BrailleGrid::new(width, height) -&gt; Result&lt;Self&gt;</signature>
      <signature>set_dot(x, y) -&gt; Result&lt;()&gt;</signature>
      <signature>clear()</signature>
      <signature>cell_to_braille_char(x, y) -&gt; Result&lt;char&gt;</signature>
      <signature>to_unicode_grid() -&gt; Vec&lt;Vec&lt;char&gt;&gt;</signature>
      <path>src/grid.rs</path>
    </interface>
    <interface name="FrameBuffer" kind="struct">
      <signature>FrameBuffer::new(width, height) -&gt; Self</signature>
      <signature>swap_buffers()</signature>
      <signature>get_back_buffer() -&gt; &amp;mut BrailleGrid</signature>
      <path>src/animation/buffer.rs</path>
    </interface>
    <interface name="FrameTimer" kind="struct">
      <signature>FrameTimer::new(target_fps) -&gt; Self</signature>
      <signature>wait_for_next_frame()</signature>
      <signature>actual_fps() -&gt; f64</signature>
      <path>src/animation/timing.rs</path>
    </interface>
    <interface name="DifferentialRenderer" kind="struct">
      <signature>DifferentialRenderer::new() -&gt; Self</signature>
      <signature>count_changed_cells(&amp;self, current, previous) -&gt; usize</signature>
      <path>src/animation/differential.rs</path>
    </interface>
    <interface name="ImageRenderer" kind="struct" feature="image">
      <signature>ImageRenderer::builder() -&gt; ImageRendererBuilder</signature>
      <signature>render_to_grid(img, width, height) -&gt; Result&lt;BrailleGrid&gt;</signature>
      <path>src/image/mod.rs</path>
    </interface>
    <interface name="GitHub Actions" kind="ci-workflow">
      <signature>.github/workflows/benchmark.yml</signature>
      <usage>Benchmark CI workflow - needs regression detection enhancement</usage>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Benchmarks use criterion 0.7 with html_reports feature. Each benchmark file follows the pattern: define benchmark functions, create criterion_group!, call criterion_main!. Use std::hint::black_box to prevent compiler optimization. Feature-gate image benchmarks with #[cfg(feature = "image")]. Benchmark names should be descriptive: "grid_creation_80x24", "swap_buffers_200x50".
    </standards>
    <locations>
      <location>benches/*.rs - All benchmark files</location>
      <location>target/criterion/ - Benchmark results (HTML reports)</location>
      <location>.github/workflows/benchmark.yml - CI benchmark workflow</location>
    </locations>
    <ideas>
      <idea ac="AC1">Create benches/core_rendering.rs with grid_creation (40x12, 80x24, 160x48, 200x50), dot_operations (1000, 10000 ops), unicode_conversion benchmarks</idea>
      <idea ac="AC2">Create benches/image_processing.rs consolidating image_load, image_resize, dither_algorithms, threshold, full_pipeline benchmarks</idea>
      <idea ac="AC3">Enhance benches/animation.rs with 60fps_sustained benchmark (100+ frames at target rate)</idea>
      <idea ac="AC4">Run cargo bench --all-features and verify all benchmarks complete without errors</idea>
      <idea ac="AC5">Measure full_pipeline_80x24 benchmark - must be &lt;25ms mean execution time</idea>
      <idea ac="AC6">Add frame timing validation benchmark - verify &lt;16.67ms per frame for 60fps</idea>
      <idea ac="AC7">Enhance benchmark.yml to run cargo bench --all-features</idea>
      <idea ac="AC8">Add criterion baseline comparison with &gt;10% regression failure threshold</idea>
      <idea ac="AC9">Add Performance section to README with benchmark table: grid_creation, image_pipeline, animation_fps</idea>
    </ideas>
  </tests>
</story-context>
